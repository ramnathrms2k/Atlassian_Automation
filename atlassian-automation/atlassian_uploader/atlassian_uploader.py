# -*- coding: utf-8 -*-
"""Atlassian Uploader

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eY0Q8Bs2bJ9x-RMhQDIflXQUczcvdhk0
"""

import os
import subprocess
import sys
import glob

# =================CONFIGURATION=================

# 1. Your Authentication Token
AUTH_TOKEN = "TOKEN"

# 2. The Jira/Premier Support Ticket Number
TICKET_ID = "PS-190255"

# 3. How many chunks to split the file into?
CHUNK_COUNT = 1

# 4. List of absolute paths to the files you want to process
FILES_TO_PROCESS = [
        "/projects/vmw-atlassian-jira/sharehome_a3/export/Confluence_conf1-prd-a1_3f0eb2af_-10-74-203-27-5801_support_2025-12-19-22-03-00.zip",
        "/projects/vmw-atlassian-jira/sharehome_a3/export/Confluence_conf1-prd-a2_3f0eb2ce_-10-74-203-28-5801_support_2025-12-19-22-03-03.zip",
        "/projects/vmw-atlassian-jira/sharehome_a3/export/Confluence_conf1-prd-a3_3f0eb2ed_-10-74-203-29-5801_support_2025-12-19-22-03-04.zip"
]

# 5. Delete chunks after successful upload to save disk space? (True/False)
DELETE_CHUNKS_AFTER_UPLOAD = True

# 6. Directory to store chunks ('.' for current dir, or None to use same dir as source file)
# Using current directory is safer if /export/ is read-only.
TEMP_CHUNK_DIR = "."

# ===============================================

def check_requirements():
    """Checks if curl and split are installed."""
    if subprocess.call("which curl > /dev/null", shell=True) != 0:
        print("Error: 'curl' is not installed or not in PATH.")
        sys.exit(1)
    if subprocess.call("which split > /dev/null", shell=True) != 0:
        print("Error: 'split' is not installed or not in PATH.")
        sys.exit(1)

def split_file(filepath, chunks, output_dir):
    """Splits the file into N chunks using the native linux split command."""
    if not os.path.exists(filepath):
        print(f"Error: File not found: {filepath}")
        return []

    print(f"--- Splitting {os.path.basename(filepath)} into {chunks} chunks ---")

    # Determine where to put chunks
    if output_dir == '.':
        output_dir = os.getcwd()
    elif output_dir is None:
        output_dir = os.path.dirname(filepath)

    base_name = os.path.basename(filepath)
    prefix = os.path.join(output_dir, f"{base_name}.part_")

    # Construct split command: split -n <chunks> -d <file> <prefix>
    cmd = ["split", "-n", str(chunks), "-d", filepath, prefix]

    try:
        subprocess.check_call(cmd)
        print(f"Splitting complete. Chunks saved to {output_dir}")
    except subprocess.CalledProcessError as e:
        print(f"Error splitting file: {e}")
        return []

    # Find the generated files
    chunk_files = sorted(glob.glob(f"{prefix}*"))
    return chunk_files

def upload_chunk(chunk_path, ticket_id, auth_token):
    """Uploads a single chunk using curl."""
    url = f"https://transfer.atlassian.com/api/upload/{ticket_id}"
    filename = os.path.basename(chunk_path)

    print(f"Uploading chunk: {filename} ...")

    # Construct curl command
    cmd = [
        "curl",
        "-u", auth_token,
        "-X", "POST",
        "--header", "Transfer-Encoding: chunked",
        "-F", f"files[]=@{chunk_path}",
        url,
        "--progress-bar",
        "|", "tee", "/dev/null"
    ]

    full_cmd = " ".join(cmd)

    try:
        ret_code = subprocess.call(full_cmd, shell=True)
        if ret_code == 0:
            print(f"Successfully uploaded: {filename}")
            return True
        else:
            print(f"Failed to upload: {filename} (Exit code {ret_code})")
            return False
    except Exception as e:
        print(f"Exception during upload: {e}")
        return False

def main():
    check_requirements()

    print(f"Starting processing of {len(FILES_TO_PROCESS)} files.")
    print(f"Ticket: {TICKET_ID}")
    print("="*60)

    for file_path in FILES_TO_PROCESS:
        print(f"\nProcessing File: {file_path}")

        chunks = split_file(file_path, CHUNK_COUNT, TEMP_CHUNK_DIR)

        if not chunks:
            print(f"Skipping {file_path} due to split errors.")
            continue

        print(f"Created {len(chunks)} chunks. Starting sequential upload...")

        all_success = True
        for chunk in chunks:
            success = upload_chunk(chunk, TICKET_ID, AUTH_TOKEN)
            if not success:
                all_success = False
                print(f"CRITICAL: Stopping uploads for {os.path.basename(file_path)} due to failure.")
                break

        if DELETE_CHUNKS_AFTER_UPLOAD and all_success:
            print("Uploads successful. Cleaning up chunks...")
            for chunk in chunks:
                if os.path.exists(chunk):
                    os.remove(chunk)
            print("Cleanup complete.")
        elif not all_success:
            print("Clean up SKIPPED because some uploads failed.")

    print("\nAll operations completed.")

if __name__ == "__main__":
    main()
